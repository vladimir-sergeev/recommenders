{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MostPopularRecommender():\n",
    "    \n",
    "    def __init__(self, train_data, validation_data, test_data):\n",
    "        self.train = train_data\n",
    "        self.validation_data = validation_data\n",
    "        self.test = test_data\n",
    "    \n",
    "    def fit(self):\n",
    "        merged = pd.merge(self.train, order_products, on='order_id')[['order_id', 'product_id']]\n",
    "        self.product_ids = merged['product_id'].value_counts().index.values.tolist()\n",
    "        \n",
    "    def predict(self, user_ids, top_k):\n",
    "        recommendations = pd.DataFrame()\n",
    "        recommendations['user_id'] = [i for i in user_ids]\n",
    "        recommendations['predictions'] = [self.product_ids[:top_k] for i in user_ids]\n",
    "        return recommendations.sort_values(by=['user_id'])\n",
    "    \n",
    "    def get_test_products(self):\n",
    "        merged = pd.merge(self.test, order_products, on='order_id')[['order_id', 'product_id']]\n",
    "        test_product_ids = merged['product_id'].value_counts().index.values.tolist()\n",
    "        return test_product_ids\n",
    "\n",
    "    def get_actual_results(self, user_ids, top_k):\n",
    "        ground_truth = self.get_test_products()\n",
    "        actual_df = pd.DataFrame()\n",
    "        actual_df['user_id'] = [i for i in user_ids]\n",
    "        actual_df['ground_truth'] = [ground_truth[:top_k] for i in user_ids]\n",
    "        return actual_df.sort_values(by=['user_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _split_indices(grouped_ratings, retriever):\n",
    "    return np.concatenate(grouped_ratings.apply(retriever).values)\n",
    "\n",
    "def split(orders):\n",
    "    grouper = orders.sort_values('order_number').groupby('user_id')\n",
    "    train_indices = _split_indices(\n",
    "        grouper,\n",
    "        lambda user_ratings: user_ratings[:int(user_ratings.shape[0] * 0.5)].index.values)\n",
    "    \n",
    "    validation_indices = _split_indices(\n",
    "        grouper,\n",
    "        lambda user_ratings: user_ratings.iloc[int(user_ratings.shape[0] * 0.5):\n",
    "                                               int(user_ratings.shape[0] * 0.75)].index.values)\n",
    "    \n",
    "    test_indices = _split_indices(\n",
    "        grouper,\n",
    "        lambda user_ratings: user_ratings.iloc[int(user_ratings.shape[0] * 0.75):].index.values)\n",
    "    \n",
    "    return train_indices, validation_indices, test_indices\n",
    "\n",
    "def save_indices():\n",
    "    # save results\n",
    "    with open('train_indices.pickle', 'wb') as out:\n",
    "        pickle.dump(train_indices, out)\n",
    "\n",
    "    with open('validation_indices.pickle', 'wb') as out:\n",
    "        pickle.dump(validation_indices, out)\n",
    "\n",
    "    with open('test_indices.pickle', 'wb') as out:\n",
    "        pickle.dump(test_indices, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data():\n",
    "    \n",
    "    products_df = pd.read_csv('products.csv')\n",
    "    orders_df = pd.read_csv('orders.csv')\n",
    "    order_products_prior_df = pd.read_csv('order_products__prior.csv')\n",
    "    order_products_train_df = pd.read_csv('order_products__train.csv')\n",
    "    order_products_df = pd.concat([order_products_prior_df, order_products_train_df])\n",
    "    \n",
    "    return products_df, orders_df, order_products_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_split_df(orders, order_products):\n",
    "\n",
    "    with open('train_indices.pickle', 'rb') as input:\n",
    "        train_indices = pickle.load(input)\n",
    "\n",
    "    with open('validation_indices.pickle', 'rb') as input:\n",
    "        validation_indices = pickle.load(input)\n",
    "\n",
    "    with open('test_indices.pickle', 'rb') as input:\n",
    "        test_indices = pickle.load(input)\n",
    "        \n",
    "    train_df = orders.loc[train_indices]\n",
    "    validation_df = orders.loc[validation_indices]\n",
    "    test_df = orders.loc[test_indices]\n",
    "    \n",
    "    return train_df, validation_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AP@k\n",
    "def apk(actual, predicted, k=10):\n",
    "    if len(predicted)>k:\n",
    "        predicted = predicted[:k]\n",
    "\n",
    "    score = 0.0\n",
    "    num_hits = 0.0\n",
    "\n",
    "    for i,p in enumerate(predicted):\n",
    "        if p in actual and p not in predicted[:i]:\n",
    "            num_hits += 1.0\n",
    "            score += num_hits / (i+1.0)\n",
    "\n",
    "    if not actual:\n",
    "        return 0.0\n",
    "\n",
    "    return score / min(len(actual), k)\n",
    "\n",
    "# MAP@K\n",
    "def mapk(actual, predicted, k=10):\n",
    "    return np.mean([apk(a,p,k) for a,p in zip(actual, predicted)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "products, orders, order_products = read_data()\n",
    "\n",
    "train_indices, validation_indices, test_indices = split(orders)\n",
    "save_indices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, valid, test = get_split_df(orders, order_products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpr = MostPopularRecommender(train, valid, test)\n",
    "mpr.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = orders['user_id'].unique()\n",
    "top_k = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = pd.merge(mpr.predict(users, top_k), mpr.get_actual_results(users, top_k), on='user_id')\n",
    "\n",
    "actual = list(merged['ground_truth'])\n",
    "predicted = list(merged['predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7588804432393893"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapk(actual, predicted, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
