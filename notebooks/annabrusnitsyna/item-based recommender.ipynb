{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy.sparse\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    with open('train_indices.pickle', 'rb') as input:\n",
    "        train_indices = pickle.load(input)\n",
    "    with open('test_indices.pickle', 'rb') as input:\n",
    "        test_indices = pickle.load(input)\n",
    "    with open('validation_indices.pickle', 'rb') as input:\n",
    "        validation_indices = pickle.load(input)\n",
    "        \n",
    "    orders = pd.read_csv('orders.csv')[['user_id', 'order_id']]\n",
    "    train_ids = orders.loc[orders.index.isin(train_indices)]['order_id']\n",
    "    test_ids = orders.loc[orders.index.isin(test_indices)]['order_id']    \n",
    "    validation_ids = orders.loc[orders.index.isin(validation_indices)]['order_id']\n",
    "    \n",
    "    order_products_prior = pd.read_csv('order_products__prior.csv')[['product_id', 'order_id']]\n",
    "    orders = pd.merge(order_products_prior, orders, on = 'order_id')\n",
    "    \n",
    "    orders_train = orders[orders['order_id'].isin(train_ids)].drop('order_id', 1).drop_duplicates()\n",
    "    users = orders_train['user_id'].values\n",
    "    items = orders_train['product_id'].values\n",
    "    user_item = scipy.sparse.csc_matrix((np.ones(orders_train.shape[0]), (users - 1, items - 1)))\n",
    "    \n",
    "    train_data = {key: [] for key in orders['user_id'].unique() - 1}\n",
    "    test_data = {key: [] for key in orders['user_id'].unique() - 1}\n",
    "    validation_data = {key: [] for key in orders['user_id'].unique() - 1}\n",
    "    \n",
    "    for data, indices in zip([train_data, test_data, validation_data], [train_ids, test_ids, validation_ids]):\n",
    "        orders_tmp = orders[orders['order_id'].isin(indices)].drop('order_id', 1).drop_duplicates()\n",
    "        for user, item in zip(orders_tmp['user_id'] - 1, orders_tmp['product_id'] - 1):\n",
    "            data[user].append(item)\n",
    "    \n",
    "    return user_item, train_data, test_data, validation_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_svd(user_item, k):\n",
    "    svd = TruncatedSVD(n_components=k)\n",
    "    US = svd.fit_transform(user_item)\n",
    "    Vt = svd.components_\n",
    "    return US, Vt, svd.explained_variance_ratio_.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bought_items(user_item):\n",
    "    bought_items = {key: [] for key in range(user_item.shape[0])}\n",
    "    for user, item in zip(*user_item.nonzero()):\n",
    "        bought_items[user].append(item)\n",
    "    return bought_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_k_recommendations_for_user(user_id, k, item_vector, bought_items):\n",
    "    item_mean = np.mean(item_vector[:, bought_items[user_id]], 1)\n",
    "    distance = cosine_distances([item_mean], item_vector.T)\n",
    "    recommendation = np.argsort(distance)[0]\n",
    "#     recommendation = recommendation[~np.in1d(recommendation, bought_items[user_id])]\n",
    "    return recommendation[:k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend(rec_number, components_number, user_number=None):\n",
    "    user_item, train_data, test_data, validation_data = load_data()\n",
    "    print(str(user_item.shape[0]) + ' users, ' + str(user_item.shape[1]) + ' items')\n",
    "    bought_items = get_bought_items(user_item)\n",
    "    \n",
    "    user_vector, item_vector, explained_variance = get_svd(user_item, components_number)\n",
    "    print('SVD explained variance = ' + str(explained_variance))\n",
    "    \n",
    "    user_num = user_number or user_item.shape[0]\n",
    "    recommendations = {key: [] for key in range(user_num)}\n",
    "    for user_id in range(user_num):\n",
    "        recommendations[user_id] = get_top_k_recommendations_for_user(user_id, rec_number, item_vector, bought_items)\n",
    "\n",
    "    mapk_value = mapk(list(train_data.values())[:user_num], recommendations.values(), rec_number)\n",
    "    print('mapk on train data ' + str(mapk_value))\n",
    "    mapk_value = mapk(list(validation_data.values())[:user_num], recommendations.values(), rec_number)\n",
    "    print('mapk on validation data ' + str(mapk_value))\n",
    "    mapk_value = mapk(list(test_data.values())[:user_num], recommendations.values(), rec_number)\n",
    "    print('mapk on test data ' + str(mapk_value))\n",
    "    \n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "206209 users, 49688 items\n",
      "SVD explained variance = 0.25253426977667354\n",
      "mapk on train data 0.01779862819664903\n",
      "mapk on validation data 0.012928296619110609\n",
      "mapk on test data 0.013361950688145628\n"
     ]
    }
   ],
   "source": [
    "predicted = recommend(10, 200, 20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "206209 users, 49688 items\n",
      "SVD explained variance = 0.614775192017869\n",
      "mapk on train data 0.018007142857142857\n",
      "mapk on validation data 0.010964285714285715\n",
      "mapk on test data 0.008951190476190475\n"
     ]
    }
   ],
   "source": [
    "predicted = recommend(10, 2000, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVD explained variance = 0.6147787835100156\n"
     ]
    }
   ],
   "source": [
    "user_item, train_data, test_data, validation_data = load_data()\n",
    "svd = TruncatedSVD(n_components=2000)\n",
    "user_vector = svd.fit_transform(user_item)\n",
    "item_vector = svd.components_\n",
    "\n",
    "print('SVD explained variance = ' + str(svd.explained_variance_ratio_.sum()))\n",
    "\n",
    "with open('user_vectors_2000.pickle', 'wb') as out:\n",
    "    pickle.dump(user_vector, out)\n",
    "with open('item_vector_2000.pickle', 'wb') as out:\n",
    "    pickle.dump(item_vector, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
