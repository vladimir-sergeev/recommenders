{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.append(Path().absolute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from item_based_recommender import ItemBasedRecommender, split\n",
    "from user_based_recommender import UserBasedRecommender\n",
    "from most_popular_recommender import MostPopularRecommender\n",
    "from ensemble import Ensemble\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders = pd.read_csv('orders.csv')\n",
    "order_products_train = pd.read_csv('order_products__train.csv')\n",
    "order_products_prior = pd.read_csv('order_products__prior.csv')\n",
    "order_products = pd.concat([order_products_train, order_products_prior])[['order_id', 'product_id']]\n",
    "order_products.to_csv('order_products.csv', index=False)\n",
    "train_indices, validation_indices, test_indices = split(orders)\n",
    "            \n",
    "orders = orders[['user_id', 'order_id']]\n",
    "train_df = pd.concat([orders.loc[train_indices], orders.loc[validation_indices]])\n",
    "train_valid_order_products = order_products[order_products['order_id'].isin(train_df['order_id'])]\n",
    "train_valid_order_products.to_csv('train_valid_order_products.csv', index=False)\n",
    "validation_df = orders.loc[validation_indices]\n",
    "test_df = orders.loc[test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(recommender, loop_num, user_num, predictions_num):\n",
    "    recommender_class_name = type(recommender).__name__\n",
    "    for i in range(loop_num):\n",
    "\n",
    "        orders = pd.read_csv('orders.csv')\n",
    "        order_products = pd.read_csv('order_products.csv')\n",
    "        train_indices, validation_indices, test_indices = split(orders)\n",
    "            \n",
    "        orders = orders[['user_id', 'order_id']]\n",
    "        train_df = pd.concat([orders.loc[np.concatenate([train_indices, validation_indices])]])\n",
    "        train_valid_order_products = order_products[order_products['order_id'].isin(train_df['order_id'])]\n",
    "        train_valid_order_products.to_csv('train_valid_order_products.csv', index=False)\n",
    "        validation_df = orders.loc[validation_indices]\n",
    "        test_df = orders.loc[test_indices]\n",
    "\n",
    "        if recommender_class_name == 'MostPopularRecommender':\n",
    "            recommender.train = train_df\n",
    "            recommender.validation = validation_df\n",
    "            recommender.test = test_df\n",
    "            recommender.order_products_df = order_products\n",
    "        if recommender_class_name == 'ItemBasedRecommender':\n",
    "            recommender.train_data = pd.merge(train_df, order_products, on='order_id')\n",
    "            recommender.validation_data = pd.merge(validation_df, order_products, on='order_id')\n",
    "            recommender.test_data = pd.merge(test_df, order_products, on='order_id')\n",
    "\n",
    "        recommender.fit()\n",
    "\n",
    "        recommendations = {key: [] for key in range(1, user_num + 1)}\n",
    "        for user_id in recommendations.keys():\n",
    "            tmp = []\n",
    "            if recommender_class_name == 'MostPopularRecommender':\n",
    "                tmp = random.sample(recommender.predict([user_id], 100)['predictions'][0], predictions_num)\n",
    "            if recommender_class_name == 'UserBasedRecommender':\n",
    "                tmp = random.sample(list(recommender.predict(user_id)[user_id]), predictions_num)\n",
    "            if recommender_class_name == 'ItemBasedRecommender':\n",
    "                tmp = random.sample(list(recommender.predict(user_id)), predictions_num)\n",
    "            recommendations[user_id] = tmp\n",
    "                \n",
    "#         пока просто сохраним предсказания\n",
    "#         потом надо будет передать их в функцию, которая добавит всё в основные таблицы\n",
    "        with open(str(predictions_num) + 'predBy' + recommender_class_name + str(i) + '.pickle', 'wb') as out:\n",
    "            pickle.dump(recommendations, out)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommender1 = MostPopularRecommender(train_df, validation_df, test_df, orders, order_products)\n",
    "pipeline(recommender1, 1, 100, 7)\n",
    "\n",
    "recommender2 = ItemBasedRecommender(train_df, validation_df, test_df)\n",
    "pipeline(recommender2, 1, 100, 7)\n",
    "\n",
    "recommender3 = UserBasedRecommender('orders.csv', 'train_valid.csv', 10)\n",
    "pipeline(recommender3, 1, 100, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_for_ensemble(loop_num, predictions_num):\n",
    "    with open('users_subsample.pickle', 'rb') as inp:\n",
    "        user_ids = pickle.load(inp)  \n",
    "            \n",
    "    for i in range(loop_num):\n",
    "\n",
    "        orders = pd.read_csv('orders.csv')\n",
    "        order_products = pd.read_csv('order_products.csv')\n",
    "        train_indices, validation_indices, test_indices = split(orders)\n",
    "            \n",
    "        orders = orders[['user_id', 'order_id']]\n",
    "        train_df = pd.concat([orders.loc[np.concatenate([train_indices, validation_indices])]])\n",
    "        train_valid_order_products = order_products[order_products['order_id'].isin(train_df['order_id'])]\n",
    "        train_valid_order_products.to_csv('train_valid_order_products.csv', index=False)\n",
    "        validation_df = orders.loc[validation_indices]\n",
    "        test_df = orders.loc[test_indices]        \n",
    "        \n",
    "        test_merged = pd.merge(test_df, order_products, on='order_id')\n",
    "        actual = dict(test_merged.groupby('user_id')['product_id'].apply(list))\n",
    "\n",
    "        mpr = MostPopularRecommender(train_df, validation_df, test_df, orders, order_products)\n",
    "        mpr.fit()\n",
    "        mpr_pred = {key: [] for key in user_ids}\n",
    "        for user in user_ids:\n",
    "            mpr_pred[user] = mpr.predict([user], 100)['predictions'][0]\n",
    "        with open('predByMostPopularRecommender' + str(i) +'.pickle', 'wb') as out:\n",
    "            pickle.dump(mpr_pred, out) \n",
    "        \n",
    "        ibr = ItemBasedRecommender(pd.merge(train_df, order_products, on='order_id'),\n",
    "                                   pd.merge(validation_df, order_products, on='order_id'),\n",
    "                                   pd.merge(test_df, order_products, on='order_id'))\n",
    "        ibr.fit()\n",
    "        ibr_pred = {key: [] for key in user_ids}\n",
    "        for user in user_ids:\n",
    "            ibr_pred[user] = ibr.predict(user)\n",
    "        with open('predByItemBasedRecommender' + str(i) +'.pickle', 'wb') as out:\n",
    "            pickle.dump(ibr_pred, out) \n",
    "        \n",
    "        ubr = UserBasedRecommender('orders.csv', 'train_valid_order_products.csv', 10)\n",
    "        ubr.fit()\n",
    "        ubr_pred = {key: [] for key in user_ids}\n",
    "        for user in user_ids:\n",
    "            ubr_pred[user] = ubr.predict(user_id=user)[user]\n",
    "        with open('predByUserBasedRecommender.pickle', 'wb') as out:\n",
    "            pickle.dump(ubr_pred, out) \n",
    "        \n",
    "        ensemble = Ensemble(mpr_pred, ibr_pred, ubr_pred, actual)\n",
    "        ensemble.fit(user_ids)\n",
    "        recommendations, models = ensemble.predict()\n",
    "        \n",
    "        for user, products in recommendations.items():\n",
    "            recommendations[user] = random.sample(list(products), predictions_num)\n",
    "        \n",
    "#         пока просто сохраним предсказания\n",
    "#         потом надо будет передать их в функцию, которая добавит всё в основные таблицы\n",
    "        with open(str(predictions_num) + 'predByEnsemble' + str(i) + '.pickle', 'wb') as out:\n",
    "            pickle.dump(recommendations, out)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
